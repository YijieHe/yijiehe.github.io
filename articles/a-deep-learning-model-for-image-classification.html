
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro:300,400,400i,700" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="../theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="../theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="../theme/font-awesome/css/font-awesome.min.css">


    <link href="https://yijiehe.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Yijie He Atom">





<meta name="author" content="Yijie" />
<meta name="description" content="Train a convolutional neural network to classify beetles, cockroach and dragonflies using tensorflow" />
<meta name="keywords" content="">

<meta property="og:site_name" content="Yijie He"/>
<meta property="og:title" content="A Deep Learning Model for Image Classification"/>
<meta property="og:description" content="Train a convolutional neural network to classify beetles, cockroach and dragonflies using tensorflow"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="../articles/a-deep-learning-model-for-image-classification.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-11-16 00:00:00+00:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="../author/yijie.html">
<meta property="article:section" content="Projects"/>
<meta property="og:image" content="">

  <title>Yijie He &ndash; A Deep Learning Model for Image Classification</title>

</head>
<body>
  <aside>
    <div>
      <a href="..">
        <img src="../theme/img/profile.png" alt="" title="">
      </a>
      <h1><a href=".."></a></h1>


      <nav>
        <ul class="list">
          <li><a href="../pages/About.html#About">About</a></li>
          <li><a href="../pages/Contact.html#Contact">Contact</a></li>
          <li><a href="../pages/Project.html#Project">Project</a></li>

          <li><a href="https://www.linkedin.com/in/yijie-he/" target="_blank">LinkedIn</a></li>
        </ul>
      </nav>

      <ul class="social">
      </ul>
    </div>


  </aside>
  <main>


<article class="single">
  <header>
      
    <h1 id="a-deep-learning-model-for-image-classification">A Deep Learning Model for Image Classification</h1>
    <p>
          Posted on Mon 16 November 2020 in <a href="../category/projects.html">Projects</a>


    </p>
  </header>


  <div>
    <div class="section" id="intro">
<h2>Intro</h2>
<p>Convolutinal networks is a class of deep learning models that is widely used for image classification. Its architecture
mimics the connectivity of neurons in human brain and visual cortex. In this blog, I will walk through
an implementation of ConvNet in python using tensorflow. The <a class="reference external" href="https://www.dropbox.com/s/fn73sj2e6c9rhf6/insects.zip?dl=0">dataset</a>
is originally from <a class="reference external" href="https://www.insectimages.org/index.cfm">Insect Images</a>. It contains images for three species of
insects: beetles, cockroach and dragonflies.</p>
</div>
<div class="section" id="data-preprocessing">
<h2>Data Preprocessing</h2>
<div class="section" id="import-data">
<h3>Import data</h3>
<pre class="code ipython3 literal-block">
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'test'</span><span class="p">,</span><span class="s1">'train'</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'beetles'</span><span class="p">,</span> <span class="s1">'cockroach'</span><span class="p">,</span> <span class="s1">'dragonflies'</span><span class="p">]:</span>
        <span class="n">count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">data_dir</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">'</span><span class="si">%s</span><span class="s1">/</span><span class="si">%s</span><span class="s1">/*.jpg'</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">))))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Images in </span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span> <span class="n">count</span><span class="p">))</span>
</pre>
<pre class="literal-block">
Images in test beetles: 60
Images in test cockroach: 60
Images in test dragonflies: 60
Images in train beetles: 460
Images in train cockroach: 240
Images in train dragonflies: 319
</pre>
</div>
<div class="section" id="load-data">
<h3>Load data</h3>
<pre class="code ipython3 literal-block">
<span class="c1">### specify image size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">img_height</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">img_width</span> <span class="o">=</span> <span class="mi">256</span>
</pre>
<pre class="code ipython3 literal-block">
<span class="c1">### test and train data</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
  <span class="s1">'./insects/test'</span><span class="p">,</span>
  <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
  <span class="s1">'./insects/train'</span><span class="p">,</span>
  <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre>
<pre class="literal-block">
Found 180 files belonging to 3 classes.
Found 1019 files belonging to 3 classes.
</pre>
<pre class="code ipython3 literal-block">
<span class="n">test_ds</span><span class="o">.</span><span class="n">class_names</span>
</pre>
<pre class="literal-block">
['beetles', 'cockroach', 'dragonflies']
</pre>
</div>
<div class="section" id="visualize-data">
<h3>Visualize data</h3>
<pre class="code ipython3 literal-block">
<span class="n">class_names</span> <span class="o">=</span> <span class="n">test_ds</span><span class="o">.</span><span class="n">class_names</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre>
<img alt="Example plot for each insect specie" src="/images/output_13_0.png" />
</div>
<div class="section" id="configure-the-dataset-for-performance">
<h3>Configure the dataset for performance</h3>
<p>By merit of offical tensorflow documentation, we buffer the data so that we can yield data from
disk without I/O become blocking.</p>
<pre class="code ipython3 literal-block">
<span class="n">AUTOTUNE</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span>

<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test_ds</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="build-the-model">
<h3>Build the model</h3>
<pre class="code ipython3 literal-block">
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(),</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(),</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(),</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
  <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
<span class="p">])</span>
</pre>
<pre class="code ipython3 literal-block">
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
</pre>
<pre class="code ipython3 literal-block">
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre>
<pre class="literal-block">
Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
rescaling_2 (Rescaling)      (None, 180, 180, 3)       0
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 180, 180, 16)      448
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 90, 90, 16)        0
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 90, 90, 32)        4640
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 45, 45, 32)        0
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 45, 45, 64)        18496
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 22, 22, 64)        0
_________________________________________________________________
flatten_2 (Flatten)          (None, 30976)             0
_________________________________________________________________
dense_4 (Dense)              (None, 128)               3965056
_________________________________________________________________
dense_5 (Dense)              (None, 3)                 387
=================================================================
Total params: 3,989,027
Trainable params: 3,989,027
Non-trainable params: 0
_________________________________________________________________
</pre>
<p><strong>tf.keras.Sequential</strong> groups a linear stack of layers. The first layer is used to normalize our
image data. Subsequent layers are comprised of <em>convolution layer</em>, <em>pooling layer</em>, <em>flatten layer</em> and
<em>dense layer</em>. Here are brief explanations of each kinds of layer.</p>
<ul>
<li><dl class="first docutils">
<dt>Convolution layer</dt>
<dd><blockquote class="first">
<p>The objective of the Convolution Operation is to extract the high-level features such as edges, from the input image.
ConvNets need not be limited to only one Convolutional Layer. Conventionally, the first ConvLayer is responsible for
capturing the Low-Level features such as edges, color, gradient orientation, etc. With added layers,
the architecture adapts to the High-Level features as well, giving us a network which has the wholesome understanding
of images in the dataset, similar to how we would. In the simple illustration shown below, the filter goes over the
input matrix and map the calculated feature into output.</p>
<img alt="explanation of conv layer" src="/images/comv.png" />
</blockquote>
<p>In our model, the first convolution layer is applying 16 3*3*3
filters to the input 256*256*3 tensor. The stride for the filters is set to 1, meaning that each filter will move
1 pixel at a time. The graph below shows how the output will be calculated.</p>
<img alt="explanation of first conv layer." class="last" src="/images/conv2.png" />
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Pooling layer</dt>
<dd><p class="first">Pooling layers section would reduce the number of parameters when the images are too large.
Spatial pooling also called subsampling or downsampling which reduces the dimensionality of each map but retains
important information. Spatial pooling can be of different types:</p>
<blockquote>
<ul class="simple">
<li>Max Pooling</li>
<li>Average Pooling</li>
<li>Sum Pooling</li>
</ul>
</blockquote>
<p>Our model uses max pooling. It takes the largest element from the rectified feature map. Taking the largest element could
also take the average pooling. Sum of all elements in the feature map call as sum pooling.</p>
<img alt="explanation of pooling." class="last" src="/images/pooling.png" />
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Fully connected layer</dt>
<dd><p class="first">Fully connected layer functions like a neural network. It first fattens the tensor from previous layer into 1-D and
the data will go through dense layers that combines all of the features to classify the outputs. The full diagram of the
model can be interpreted as:</p>
<img alt="explanation of pooling." class="last" src="/images/fc.jpeg" />
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="train-the-model">
<h3>Train the model</h3>
<pre class="code ipython3 literal-block">
<span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
  <span class="n">train_ds</span><span class="p">,</span>
  <span class="n">validation_data</span><span class="o">=</span><span class="n">test_ds</span><span class="p">,</span>
  <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span>
<span class="p">)</span>
</pre>
<pre class="literal-block">
Epoch 1/10
32/32 [==============================] - 9s 273ms/step - loss: 0.8813 - accuracy: 0.6359 - val_loss: 0.7354 - val_accuracy: 0.7056
Epoch 2/10
32/32 [==============================] - 8s 258ms/step - loss: 0.4250 - accuracy: 0.8420 - val_loss: 0.5449 - val_accuracy: 0.7944
Epoch 3/10
32/32 [==============================] - 8s 256ms/step - loss: 0.3335 - accuracy: 0.8685 - val_loss: 0.3164 - val_accuracy: 0.8833
Epoch 4/10
32/32 [==============================] - 8s 252ms/step - loss: 0.2155 - accuracy: 0.9244 - val_loss: 0.2794 - val_accuracy: 0.9056
Epoch 5/10
32/32 [==============================] - 8s 253ms/step - loss: 0.1634 - accuracy: 0.9352 - val_loss: 0.2488 - val_accuracy: 0.9000
Epoch 6/10
32/32 [==============================] - 8s 258ms/step - loss: 0.1062 - accuracy: 0.9686 - val_loss: 0.1566 - val_accuracy: 0.9556
Epoch 7/10
32/32 [==============================] - 8s 254ms/step - loss: 0.0662 - accuracy: 0.9823 - val_loss: 0.0514 - val_accuracy: 0.9889
Epoch 8/10
32/32 [==============================] - 8s 255ms/step - loss: 0.0464 - accuracy: 0.9882 - val_loss: 0.0574 - val_accuracy: 0.9889
Epoch 9/10
32/32 [==============================] - 8s 255ms/step - loss: 0.0410 - accuracy: 0.9892 - val_loss: 0.0417 - val_accuracy: 0.9889
Epoch 10/10
32/32 [==============================] - 8s 253ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 0.0360 - val_accuracy: 0.9889
</pre>
</div>
<div class="section" id="visualize-result">
<h3>Visualize result</h3>
<p>Accuracy and loss of the model during each epoch is plotted below. Since the training and validation accuracy are close,
there is no potential overfitting of our model. The final accuracy is nearly 100%, so it performs rather well on our dataset.</p>
<pre class="code ipython3 literal-block">
<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">]</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_loss'</span><span class="p">]</span>

<span class="n">epochs_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs_range</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training Accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs_range</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Validation Accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training and Validation Accuracy'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs_range</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs_range</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Validation Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training and Validation Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre>
<img alt="Model performance" src="/images/output_24_0.png" />
</div>
<div class="section" id="references">
<h3>References</h3>
<p><a class="reference external" href="https://www.tensorflow.org/tutorials/images/classification">https://www.tensorflow.org/tutorials/images/classification</a></p>
<p><a class="reference external" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53</a></p>
<p><a class="reference external" href="https://medium.com/&#64;RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148">https://medium.com/&#64;RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148</a></p>
</div>
</div>

  </div>
  <div class="tag-cloud">
    <p>
    </p>
  </div>





</article>

    <footer>
<p>&copy;  </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Yijie He ",
  "url" : "..",
  "image": "",
  "description": ""
}
</script>

</body>
</html>